{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RepnaiaE/DataScience_Emotion-recognition-methods/blob/main/Lab4_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4cSq6JDETg8z"
      },
      "id": "4cSq6JDETg8z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Классификация. Метод опорных векторов (SVM), ядерный SVM. Байесовский классификатор. Классификатор на основе К ближайших соседей (KNN). Деревья решений. Упрощение деревьев. Случайный лес. Оценка эффективности и сравнение моделей. /Classification. Support vector machine (SVM), kernel SVM. Bayesian classifier. Classifier based on K nearest neighbors (KNN). decision trees. Simplifying trees. Random forest. Evaluation of efficiency and comparison of models."
      ],
      "metadata": {
        "id": "AiiA-_WnyLYx"
      },
      "id": "AiiA-_WnyLYx"
    },
    {
      "cell_type": "markdown",
      "id": "a174cad7",
      "metadata": {
        "id": "a174cad7"
      },
      "source": [
        "# Загрузка данных/Loading data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "401ae3f9",
      "metadata": {
        "id": "401ae3f9"
      },
      "source": [
        "Загружаем данные из ячеек в массивы признаков для каждого набора из предыдущей работы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60f40afc",
      "metadata": {
        "scrolled": true,
        "id": "60f40afc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "ling_features = pd.read_csv(r'C:\\Users\\voloshina\\Documents\\Notebooks\\Распознавание эмоций\\Распознавание эмоций\\ru_tweet_corp_ling_features.csv').sample(frac=1)\n",
        "ling_features_vec = list(ling_features['features'].apply(lambda y: [float(x) for x in y[1:len(y)-1].split(',')]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f634565",
      "metadata": {
        "scrolled": true,
        "id": "6f634565"
      },
      "outputs": [],
      "source": [
        "morph_features = pd.read_csv(r'C:\\Users\\voloshina\\Documents\\Notebooks\\Распознавание эмоций\\Распознавание эмоций\\ru_tweet_corp_morph_features.csv').sample(frac=1)\n",
        "morph_features_vec = list(morph_features['coded_pos'].apply(lambda y: [float(x) for x in y[1:len(y)-1].split(',')]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef22b548",
      "metadata": {
        "scrolled": true,
        "id": "ef22b548"
      },
      "outputs": [],
      "source": [
        "tfidf_features = pd.read_csv(r'C:\\Users\\voloshina\\Documents\\Notebooks\\Распознавание эмоций\\Распознавание эмоций\\ru_tweet_corp_tfidf.csv').sample(frac=1)\n",
        "tfidf_features_vec = list(tfidf_features['tfidf'].apply(lambda y: [float(x) for x in y[1:len(y)-1].split(',')]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13b7cde3",
      "metadata": {
        "scrolled": false,
        "id": "13b7cde3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "concated_features = pd.read_csv(r'C:\\Users\\voloshina\\Documents\\Notebooks\\Распознавание эмоций\\Распознавание эмоций\\ru_tweet_corp_tfidf.csv').sample(frac=1)\n",
        "\n",
        "features_tfidf = list(concated_features['tfidf'].apply(lambda y: [float(x) for x in y[1:len(y)-1].split(',')]))\n",
        "morph_features_coded_pos = list(concated_features['coded_pos'].apply(lambda y: [float(x) for x in y[1:len(y)-1].split(',')]))\n",
        "ling_features_features = list(concated_features['features'].apply(lambda y: [float(x) for x in y[1:len(y)-1].split(',')]))\n",
        "\n",
        "concated_features_vec = []\n",
        "for tf, morph, ling in zip(features_tfidf, morph_features_coded_pos, ling_features_features):\n",
        "    concated_features_vec.append(tf + morph + ling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3863f942",
      "metadata": {
        "id": "3863f942",
        "outputId": "95af5292-cf1b-48ff-c2c1-e48f7cb0d45c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1023"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(concated_features_vec[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8f96801",
      "metadata": {
        "id": "c8f96801"
      },
      "source": [
        "# Классификаторы/Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1ce6053",
      "metadata": {
        "id": "d1ce6053"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "\n",
        "def calc_clfs(features, y, test_size=200):\n",
        "    X = features[:len(features) - test_size]\n",
        "    y = list(y)[:len(y) - test_size]\n",
        "\n",
        "    for_pred_x = features[len(features) - test_size:len(features)]\n",
        "    expected_y = list(y)[len(y) - test_size:len(y)]\n",
        "\n",
        "    svm_clf = svm.SVC()\n",
        "    svm_clf.fit(X, y)\n",
        "    y_pred = svm_clf.predict(for_pred_x)\n",
        "#     print(f'svm prediction {y_pred}, expected {expected_y}')\n",
        "    print('metrics for svm:')\n",
        "    print(f'accuracy = {accuracy_score(expected_y, y_pred)}')\n",
        "    print(f'recall = {recall_score(expected_y, y_pred)}')\n",
        "    print(f'precision = {precision_score(expected_y, y_pred)}')\n",
        "    print(f'f1 = {f1_score(expected_y, y_pred)}')\n",
        "\n",
        "    print()\n",
        "\n",
        "    tree_clf = DecisionTreeClassifier(criterion='entropy', max_depth=10, random_state=0)\n",
        "    tree_clf.fit(X, y)\n",
        "    y_pred = tree_clf.predict(for_pred_x)\n",
        "#     print(f'tree prediction {y_pred}, expected {expected_y}')\n",
        "    print('metrics for tree:')\n",
        "    print(f'accuracy = {accuracy_score(expected_y, y_pred)}')\n",
        "    print(f'recall = {recall_score(expected_y, y_pred)}')\n",
        "    print(f'precision = {precision_score(expected_y, y_pred)}')\n",
        "    print(f'f1 = {f1_score(expected_y, y_pred)}')\n",
        "\n",
        "    print()\n",
        "\n",
        "    forest_clf = RandomForestClassifier(max_depth=5, random_state=0)\n",
        "    forest_clf.fit(X, y)\n",
        "    y_pred = forest_clf.predict(for_pred_x)\n",
        "#     print(f'forest prediction {y_pred}, expected {expected_y}')\n",
        "    print('metrics for forest:')\n",
        "    print(f'accuracy = {accuracy_score(expected_y, y_pred)}')\n",
        "    print(f'recall = {recall_score(expected_y, y_pred)}')\n",
        "    print(f'precision = {precision_score(expected_y, y_pred)}')\n",
        "    print(f'f1 = {f1_score(expected_y, y_pred)}')\n",
        "\n",
        "    print()\n",
        "\n",
        "#     transformer = Normalizer(norm='max').fit(X)\n",
        "#     XX =  transformer.transform(X)\n",
        "#     XX = [list(map(abs, x)) for x in X]\n",
        "    scaler = MinMaxScaler()\n",
        "    XX = scaler.fit_transform(X)\n",
        "\n",
        "    bayes_clf = MultinomialNB()\n",
        "    bayes_clf.fit(XX, y)\n",
        "    y_pred = bayes_clf.predict(for_pred_x)\n",
        "#     print(f'bayes prediction {y_pred}, expected {expected_y}')\n",
        "    print('metrics for bayes:')\n",
        "    print(f'accuracy = {accuracy_score(expected_y, y_pred)}')\n",
        "    print(f'recall = {recall_score(expected_y, y_pred)}')\n",
        "    print(f'precision = {precision_score(expected_y, y_pred)}')\n",
        "    print(f'f1 = {f1_score(expected_y, y_pred)}')\n",
        "\n",
        "    print()\n",
        "\n",
        "    knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
        "    knn_clf.fit(X, y)\n",
        "    y_pred = knn_clf.predict(for_pred_x)\n",
        "#     print(f'KNN prediction {y_pred}, expected {expected_y}')\n",
        "    print('metrics for knn:')\n",
        "    print(f'accuracy = {accuracy_score(expected_y, y_pred)}')\n",
        "    print(f'recall = {recall_score(expected_y, y_pred)}')\n",
        "    print(f'precision = {precision_score(expected_y, y_pred)}')\n",
        "    print(f'f1 = {f1_score(expected_y, y_pred)}')\n",
        "\n",
        "    print()\n",
        "\n",
        "    f1 = make_scorer(f1_score , average='macro')\n",
        "\n",
        "    parameters = {'kernel':('linear', 'rbf'),\n",
        "                  'C':[i for i in range(1, 10, 2)]}\n",
        "    clf_svm = GridSearchCV(svm_clf, parameters, scoring=f1)\n",
        "    clf_svm.fit(X, y)\n",
        "    print('for svm: ')\n",
        "    print(f'best score {clf_svm.best_score_}')\n",
        "    print(f'best params {clf_svm.best_params_}')\n",
        "\n",
        "    print()\n",
        "\n",
        "    parameters = {'criterion':('gini', 'entropy'),\n",
        "                  'max_depth':[i for i in range(3, 10, 2)]}\n",
        "    clf_tree = GridSearchCV(tree_clf, parameters, scoring=f1)\n",
        "    clf_tree.fit(X, y)\n",
        "    print('for tree: ')\n",
        "    print(f'best score {clf_tree.best_score_}')\n",
        "    print(f'best params {clf_tree.best_params_}')\n",
        "\n",
        "    print()\n",
        "\n",
        "    parameters = {'criterion':('gini', 'entropy'),\n",
        "                  'max_depth':[i for i in range(2, 10, 2)],\n",
        "                  'n_estimators':[i for i in range(10, 100, 10)]}\n",
        "    clf_forest = GridSearchCV(forest_clf, parameters, scoring=f1)\n",
        "    clf_forest.fit(X, y)\n",
        "    print('for forest: ')\n",
        "    print(f'best score {clf_forest.best_score_}')\n",
        "    print(f'best params {clf_forest.best_params_}')\n",
        "\n",
        "    print()\n",
        "\n",
        "    parameters = {'alpha':[0.0, 0.2, 0.5, 0.7, 1.0]}\n",
        "    clf_bayes = GridSearchCV(bayes_clf, parameters, scoring=f1)\n",
        "    clf_bayes.fit(XX, y)\n",
        "    print('for bayes: ')\n",
        "    print(f'best score {clf_bayes.best_score_}')\n",
        "    print(f'best params {clf_bayes.best_params_}')\n",
        "\n",
        "    print()\n",
        "\n",
        "    parameters = {'weights':('uniform', 'distance'),\n",
        "                  'algorithm':('auto', 'kd_tree', 'brute'),\n",
        "                  'n_neighbors':[i for i in range(1, 10, 1)]}\n",
        "    clf_knn = GridSearchCV(knn_clf, parameters, scoring=f1)\n",
        "    clf_knn.fit(X, y)\n",
        "    print('for knn: ')\n",
        "    print(f'best score {clf_knn.best_score_}')\n",
        "    print(f'best params {clf_knn.best_params_}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7df00cab",
      "metadata": {
        "id": "7df00cab"
      },
      "source": [
        "Лингвистические признаки/Linguistic features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a4df95c",
      "metadata": {
        "id": "3a4df95c",
        "outputId": "0d752ae4-093e-421a-e8af-1878b2def6f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "metrics for svm:\n",
            "accuracy = 0.5\n",
            "recall = 0.7387387387387387\n",
            "precision = 0.5359477124183006\n",
            "f1 = 0.6212121212121212\n",
            "\n",
            "metrics for tree:\n",
            "accuracy = 0.525\n",
            "recall = 0.6756756756756757\n",
            "precision = 0.5597014925373134\n",
            "f1 = 0.6122448979591837\n",
            "\n",
            "metrics for forest:\n",
            "accuracy = 0.515\n",
            "recall = 0.7027027027027027\n",
            "precision = 0.5492957746478874\n",
            "f1 = 0.6166007905138341\n",
            "\n",
            "metrics for bayes:\n",
            "accuracy = 0.5\n",
            "recall = 0.6846846846846847\n",
            "precision = 0.5390070921985816\n",
            "f1 = 0.6031746031746031\n",
            "\n",
            "metrics for knn:\n",
            "accuracy = 0.44\n",
            "recall = 0.24324324324324326\n",
            "precision = 0.4909090909090909\n",
            "f1 = 0.3253012048192771\n",
            "\n",
            "for svm: \n",
            "best score 0.5359167739156953\n",
            "best params {'C': 3, 'kernel': 'linear'}\n",
            "\n",
            "for tree: \n",
            "best score 0.4891658372985336\n",
            "best params {'criterion': 'gini', 'max_depth': 7}\n",
            "\n",
            "for forest: \n",
            "best score 0.5264853838335243\n",
            "best params {'criterion': 'gini', 'max_depth': 4, 'n_estimators': 10}\n",
            "\n",
            "for bayes: \n",
            "best score 0.5141906682695093\n",
            "best params {'alpha': 0.0}\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  warnings.warn('alpha too small will result in numeric errors, '\n",
            "A:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  warnings.warn('alpha too small will result in numeric errors, '\n",
            "A:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  warnings.warn('alpha too small will result in numeric errors, '\n",
            "A:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  warnings.warn('alpha too small will result in numeric errors, '\n",
            "A:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  warnings.warn('alpha too small will result in numeric errors, '\n",
            "A:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  warnings.warn('alpha too small will result in numeric errors, '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for knn: \n",
            "best score 0.5385413182880072\n",
            "best params {'algorithm': 'brute', 'n_neighbors': 9, 'weights': 'uniform'}\n"
          ]
        }
      ],
      "source": [
        "calc_clfs(ling_features_vec, ling_features['ttype'].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4adde9e",
      "metadata": {
        "id": "e4adde9e"
      },
      "source": [
        "Морфологические признаки/Morphological features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d08da128",
      "metadata": {
        "id": "d08da128",
        "outputId": "fcb85555-75c7-4acc-94c8-5a6dace4fdce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "metrics for svm:\n",
            "accuracy = 0.515\n",
            "recall = 0.5360824742268041\n",
            "precision = 0.5\n",
            "f1 = 0.5174129353233832\n",
            "\n",
            "metrics for tree:\n",
            "accuracy = 0.58\n",
            "recall = 0.5670103092783505\n",
            "precision = 0.5670103092783505\n",
            "f1 = 0.5670103092783505\n",
            "\n",
            "metrics for forest:\n",
            "accuracy = 0.535\n",
            "recall = 0.5360824742268041\n",
            "precision = 0.52\n",
            "f1 = 0.5279187817258884\n",
            "\n",
            "metrics for bayes:\n",
            "accuracy = 0.525\n",
            "recall = 0.6288659793814433\n",
            "precision = 0.5083333333333333\n",
            "f1 = 0.5622119815668203\n",
            "\n",
            "metrics for knn:\n",
            "accuracy = 0.53\n",
            "recall = 0.5154639175257731\n",
            "precision = 0.5154639175257731\n",
            "f1 = 0.5154639175257731\n",
            "\n",
            "for svm: \n",
            "best score 0.5832741384962992\n",
            "best params {'C': 7, 'kernel': 'rbf'}\n",
            "\n",
            "for tree: \n",
            "best score 0.5434858127590749\n",
            "best params {'criterion': 'entropy', 'max_depth': 9}\n",
            "\n",
            "for forest: \n",
            "best score 0.5909152487440459\n",
            "best params {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 90}\n",
            "\n",
            "for bayes: \n",
            "best score 0.5776812380697776\n",
            "best params {'alpha': 0.2}\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  warnings.warn('alpha too small will result in numeric errors, '\n",
            "A:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  warnings.warn('alpha too small will result in numeric errors, '\n",
            "A:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  warnings.warn('alpha too small will result in numeric errors, '\n",
            "A:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  warnings.warn('alpha too small will result in numeric errors, '\n",
            "A:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  warnings.warn('alpha too small will result in numeric errors, '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for knn: \n",
            "best score 0.5570535248805879\n",
            "best params {'algorithm': 'auto', 'n_neighbors': 1, 'weights': 'uniform'}\n"
          ]
        }
      ],
      "source": [
        "calc_clfs(morph_features_vec, morph_features['ttype'].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a67de71",
      "metadata": {
        "id": "0a67de71"
      },
      "source": [
        "TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7943f1be",
      "metadata": {
        "id": "7943f1be",
        "outputId": "75e866a7-3da9-4478-e7f0-3cad57025aa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "metrics for svm:\n",
            "accuracy = 0.56\n",
            "recall = 0.5894736842105263\n",
            "precision = 0.5333333333333333\n",
            "f1 = 0.5599999999999999\n",
            "\n",
            "metrics for tree:\n",
            "accuracy = 0.52\n",
            "recall = 0.17894736842105263\n",
            "precision = 0.4857142857142857\n",
            "f1 = 0.26153846153846155\n",
            "\n",
            "metrics for forest:\n",
            "accuracy = 0.515\n",
            "recall = 0.29473684210526313\n",
            "precision = 0.4827586206896552\n",
            "f1 = 0.3660130718954248\n",
            "\n",
            "metrics for bayes:\n",
            "accuracy = 0.55\n",
            "recall = 0.6\n",
            "precision = 0.5229357798165137\n",
            "f1 = 0.5588235294117647\n",
            "\n",
            "metrics for knn:\n",
            "accuracy = 0.48\n",
            "recall = 0.9578947368421052\n",
            "precision = 0.47643979057591623\n",
            "f1 = 0.6363636363636364\n",
            "\n",
            "for svm: \n",
            "best score 0.6632875355153708\n",
            "best params {'C': 1, 'kernel': 'rbf'}\n",
            "\n",
            "for tree: \n",
            "best score 0.5126206043571685\n",
            "best params {'criterion': 'gini', 'max_depth': 9}\n",
            "\n",
            "for forest: \n",
            "best score 0.6089883593798066\n",
            "best params {'criterion': 'gini', 'max_depth': 8, 'n_estimators': 90}\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  warnings.warn('alpha too small will result in numeric errors, '\n",
            "A:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  warnings.warn('alpha too small will result in numeric errors, '\n",
            "A:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  warnings.warn('alpha too small will result in numeric errors, '\n",
            "A:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  warnings.warn('alpha too small will result in numeric errors, '\n",
            "A:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  warnings.warn('alpha too small will result in numeric errors, '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for bayes: \n",
            "best score 0.6498811250200893\n",
            "best params {'alpha': 1.0}\n",
            "\n",
            "for knn: \n",
            "best score 0.5145948493346595\n",
            "best params {'algorithm': 'kd_tree', 'n_neighbors': 2, 'weights': 'distance'}\n"
          ]
        }
      ],
      "source": [
        "calc_clfs(tfidf_features_vec, tfidf_features['ttype'].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4866f019",
      "metadata": {
        "id": "4866f019"
      },
      "source": [
        "Concat 3 features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5028301b",
      "metadata": {
        "id": "5028301b",
        "outputId": "a5716901-514c-421d-bb6c-7e8328c089cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "metrics for svm:\n",
            "accuracy = 0.5\n",
            "recall = 0.46\n",
            "precision = 0.5\n",
            "f1 = 0.4791666666666667\n",
            "\n",
            "metrics for tree:\n",
            "accuracy = 0.53\n",
            "recall = 0.62\n",
            "precision = 0.5254237288135594\n",
            "f1 = 0.5688073394495413\n",
            "\n",
            "metrics for forest:\n",
            "accuracy = 0.53\n",
            "recall = 0.45\n",
            "precision = 0.5357142857142857\n",
            "f1 = 0.4891304347826087\n",
            "\n",
            "metrics for bayes:\n",
            "accuracy = 0.495\n",
            "recall = 0.47\n",
            "precision = 0.49473684210526314\n",
            "f1 = 0.482051282051282\n",
            "\n",
            "metrics for knn:\n",
            "accuracy = 0.45\n",
            "recall = 0.59\n",
            "precision = 0.4609375\n",
            "f1 = 0.5175438596491228\n",
            "\n",
            "for svm: \n",
            "best score 0.663996620417442\n",
            "best params {'C': 3, 'kernel': 'rbf'}\n",
            "\n",
            "for tree: \n",
            "best score 0.5896492350940675\n",
            "best params {'criterion': 'entropy', 'max_depth': 9}\n",
            "\n",
            "for forest: \n",
            "best score 0.6503649680707259\n",
            "best params {'criterion': 'entropy', 'max_depth': 8, 'n_estimators': 50}\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  warnings.warn('alpha too small will result in numeric errors, '\n",
            "A:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  warnings.warn('alpha too small will result in numeric errors, '\n",
            "A:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  warnings.warn('alpha too small will result in numeric errors, '\n",
            "A:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  warnings.warn('alpha too small will result in numeric errors, '\n",
            "A:\\Anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  warnings.warn('alpha too small will result in numeric errors, '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for bayes: \n",
            "best score 0.6531511310683333\n",
            "best params {'alpha': 1.0}\n",
            "\n",
            "for knn: \n",
            "best score 0.6132040584231034\n",
            "best params {'algorithm': 'auto', 'n_neighbors': 8, 'weights': 'uniform'}\n"
          ]
        }
      ],
      "source": [
        "calc_clfs(concated_features_vec, concated_features['ttype'].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47ad376b",
      "metadata": {
        "id": "47ad376b"
      },
      "source": [
        "# Выводы/Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6164556",
      "metadata": {
        "id": "b6164556"
      },
      "source": [
        "По результатам экспериментов лучшими подходами для классификации тональности по каждому набору признаков стали:\n",
        "\n",
        "| Features | Model| Params | F1 score |\n",
        "|----------|------|--------|----------|\n",
        "| Лингвистические | SVM | без доп.настройки | 0.62 |\n",
        "| Морфологические | Random forest | 'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 90 | 0.59 |\n",
        "| TF-IDF | SVM | 'C': 1, 'kernel': 'rbf' | 0.66 |\n",
        "| Объединение признаков | SVM | 'C': 3, 'kernel': 'rbf' | 0.66 |\n",
        "\n",
        "Как итог, хотя многие модели оказываются сопоставимы по качеству распознавания, SVM показывает чуть лучшие результаты.\n",
        "\n",
        "Среди способов выделения признаков выделяется TF-IDF и объединение всех 3 векторов признаков. Хотя по результатам обучения кажется, что основной вклад в объединенном векторе внесли именно TF-IDF признаки и остались на том же уровне. Добавление новых признаков качество классификации не улучшило.\n",
        "\n",
        "As a result, although many models are comparable in terms of recognition quality, SVM shows slightly better results.\n",
        "\n",
        "Among the methods of feature extraction, TF-IDF and the union of all 3 feature vectors stand out. Although, according to the training results, it seems that the TF-IDF features made the main contribution to the combined vector and remained at the same level. The addition of new features did not improve the classification quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "893c8ebb",
      "metadata": {
        "id": "893c8ebb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
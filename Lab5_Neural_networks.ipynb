{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RepnaiaE/DataScience_Emotion-recognition-methods/blob/main/Lab5_Neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Нейронные сети. Нейронная сеть прямого распространения./Neural networks. Neural network of direct distribution."
      ],
      "metadata": {
        "id": "m5pP_T-EzFV0"
      },
      "id": "m5pP_T-EzFV0"
    },
    {
      "cell_type": "markdown",
      "id": "ed53763a",
      "metadata": {
        "id": "ed53763a"
      },
      "source": [
        "# Загрузка данных/Loading data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fe2fbf6",
      "metadata": {
        "id": "8fe2fbf6"
      },
      "source": [
        "Загружаем данные из ячеек в массивы признаков для каждого набора из предыдущей работы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1949ed17",
      "metadata": {
        "id": "1949ed17"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "ling_features = pd.read_csv(r'C:\\Users\\voloshina\\Documents\\Notebooks\\Распознавание эмоций\\Распознавание эмоций\\ru_tweet_corp_ling_features.csv').sample(frac=1)\n",
        "ling_features_vec = list(ling_features['features'].apply(lambda y: [float(x) for x in y[1:len(y)-1].split(',')]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09a4bbd9",
      "metadata": {
        "id": "09a4bbd9"
      },
      "outputs": [],
      "source": [
        "morph_features = pd.read_csv(r'C:\\Users\\voloshina\\Documents\\Notebooks\\Распознавание эмоций\\Распознавание эмоций\\ru_tweet_corp_morph_features.csv').sample(frac=1)\n",
        "morph_features_vec = list(morph_features['coded_pos'].apply(lambda y: [float(x) for x in y[1:len(y)-1].split(',')]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a86e9f84",
      "metadata": {
        "id": "a86e9f84"
      },
      "outputs": [],
      "source": [
        "tfidf_features = pd.read_csv(r'C:\\Users\\voloshina\\Documents\\Notebooks\\Распознавание эмоций\\Распознавание эмоций\\ru_tweet_corp_tfidf.csv').sample(frac=1)\n",
        "tfidf_features_vec = list(tfidf_features['tfidf'].apply(lambda y: [float(x) for x in y[1:len(y)-1].split(',')]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7383dfa5",
      "metadata": {
        "id": "7383dfa5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "concated_features = pd.read_csv(r'C:\\Users\\voloshina\\Documents\\Notebooks\\Распознавание эмоций\\Распознавание эмоций\\ru_tweet_corp_tfidf.csv').sample(frac=1)\n",
        "\n",
        "features_tfidf = list(concated_features['tfidf'].apply(lambda y: [float(x) for x in y[1:len(y)-1].split(',')]))\n",
        "morph_features_coded_pos = list(concated_features['coded_pos'].apply(lambda y: [float(x) for x in y[1:len(y)-1].split(',')]))\n",
        "ling_features_features = list(concated_features['features'].apply(lambda y: [float(x) for x in y[1:len(y)-1].split(',')]))\n",
        "\n",
        "concated_features_vec = []\n",
        "for tf, morph, ling in zip(features_tfidf, morph_features_coded_pos, ling_features_features):\n",
        "    concated_features_vec.append(tf + morph + ling)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9c9ee2f",
      "metadata": {
        "id": "c9c9ee2f"
      },
      "source": [
        "# Подготовка данных/Data preparation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5204f73",
      "metadata": {
        "scrolled": true,
        "id": "d5204f73",
        "outputId": "3448f183-1f26-4890-bde0-ebba96f4ebb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in a:\\anaconda\\lib\\site-packages (0.12.0)\n",
            "Requirement already satisfied: numpy in a:\\anaconda\\lib\\site-packages (from torchvision) (1.20.3)\n",
            "Requirement already satisfied: typing-extensions in a:\\anaconda\\lib\\site-packages (from torchvision) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in a:\\anaconda\\lib\\site-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: requests in a:\\anaconda\\lib\\site-packages (from torchvision) (2.26.0)\n",
            "Requirement already satisfied: torch==1.11.0 in a:\\anaconda\\lib\\site-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in a:\\anaconda\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in a:\\anaconda\\lib\\site-packages (from requests->torchvision) (1.26.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in a:\\anaconda\\lib\\site-packages (from requests->torchvision) (3.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in a:\\anaconda\\lib\\site-packages (from requests->torchvision) (2.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65342110",
      "metadata": {
        "id": "65342110"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import scipy\n",
        "import torch.utils.data as data_utils\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c7a0ce8",
      "metadata": {
        "id": "1c7a0ce8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def getDataLoaders(X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
        "    inputs_train = torch.tensor(X_train)\n",
        "    targets_train = torch.IntTensor(y_train)\n",
        "\n",
        "    inputs_test = torch.tensor(X_test)\n",
        "    targets_test = torch.IntTensor(y_test)\n",
        "\n",
        "    train = data_utils.TensorDataset(inputs_train, targets_train)\n",
        "    test = data_utils.TensorDataset(inputs_test, targets_test)\n",
        "\n",
        "    trainset = torch.utils.data.DataLoader(train, shuffle=True)\n",
        "    testset = torch.utils.data.DataLoader(test, shuffle=False)\n",
        "\n",
        "    return trainset, testset, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34753e15",
      "metadata": {
        "id": "34753e15"
      },
      "source": [
        "Метка -1 (негативный) переведена в 0 для дальнейшей классификации:\n",
        "\n",
        "-1 -> 0 (negative)\n",
        "\n",
        " 1 (positive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1a76e50",
      "metadata": {
        "id": "d1a76e50"
      },
      "outputs": [],
      "source": [
        "ling_train_set, ling_test_set, ling_test_y = getDataLoaders(ling_features_vec,\n",
        "                                                            [(0 if x == -1 else x) for x in ling_features['ttype'].values])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e86ba164",
      "metadata": {
        "id": "e86ba164"
      },
      "outputs": [],
      "source": [
        "morph_train_set, morph_test_set, morph_test_y = getDataLoaders(morph_features_vec,\n",
        "                                                               [(0 if x == -1 else x) for x in morph_features['ttype'].values])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1808ef3f",
      "metadata": {
        "id": "1808ef3f"
      },
      "outputs": [],
      "source": [
        "tf_idf_train_set, tf_idf_test_set, tf_idf_test_y = getDataLoaders(tfidf_features_vec,\n",
        "                                                                  [(0 if x == -1 else x) for x in tfidf_features['ttype'].values])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "537396ad",
      "metadata": {
        "id": "537396ad"
      },
      "source": [
        "# Модель/Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "292bb482",
      "metadata": {
        "id": "292bb482"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b5b820f",
      "metadata": {
        "id": "1b5b820f"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b182ac2c",
      "metadata": {
        "id": "b182ac2c",
        "outputId": "9e9fdf79-a3cd-434f-839f-7bc5d02616b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=6, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (fc3): Linear(in_features=32, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "lingNet = Net(len(ling_features_vec[0]), 32, NUM_CLASSES)\n",
        "print(lingNet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a739d48",
      "metadata": {
        "id": "0a739d48",
        "outputId": "ca5e57cc-3dee-4957-a454-ede90082a502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=17, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (fc3): Linear(in_features=32, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "morphNet = Net(len(morph_features_vec[0]), 32, NUM_CLASSES)\n",
        "print(morphNet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3d26b2b",
      "metadata": {
        "id": "d3d26b2b",
        "outputId": "2ee8098a-2e02-4565-c118-d13411a24234"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=1000, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (fc3): Linear(in_features=32, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "tfIdfNet = Net(len(tfidf_features_vec[0]), 32, NUM_CLASSES)\n",
        "print(tfIdfNet)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0b35137",
      "metadata": {
        "id": "a0b35137"
      },
      "source": [
        "# Обучение/Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "189b4df8",
      "metadata": {
        "id": "189b4df8"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def train(net, trainset, testset, y_test, epochs=3):\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    # train\n",
        "    for epoch in range(epochs):\n",
        "        for data in trainset:\n",
        "            X, y = data\n",
        "\n",
        "            net.zero_grad()\n",
        "            output = net(X.float())\n",
        "            loss = F.nll_loss(output, y.long())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"train loss {loss} for epoch {epoch}\")\n",
        "\n",
        "    # test\n",
        "    ams = []\n",
        "    with torch.no_grad():\n",
        "        for data in testset:\n",
        "            X, y = data\n",
        "\n",
        "            output = net(X.float())\n",
        "            for idx, i in enumerate(output):\n",
        "                ams.append(torch.argmax(i).item())\n",
        "\n",
        "    print(len(ams))\n",
        "    print(classification_report(y_test, ams))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c30728b1",
      "metadata": {
        "id": "c30728b1",
        "outputId": "774cc51a-bcd0-43a5-d187-0b2c71580255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.6742783188819885 for epoch 0\n",
            "train loss 0.6783490777015686 for epoch 1\n",
            "train loss 0.6560860276222229 for epoch 2\n",
            "train loss 0.734861433506012 for epoch 3\n",
            "train loss 0.6706293821334839 for epoch 4\n",
            "train loss 0.6847732067108154 for epoch 5\n",
            "train loss 0.45956870913505554 for epoch 6\n",
            "train loss 0.9584934711456299 for epoch 7\n",
            "train loss 0.6887816190719604 for epoch 8\n",
            "train loss 0.7434947490692139 for epoch 9\n",
            "400\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.30      0.41       208\n",
            "           1       0.52      0.82      0.63       192\n",
            "\n",
            "    accuracy                           0.55       400\n",
            "   macro avg       0.58      0.56      0.52       400\n",
            "weighted avg       0.58      0.55      0.52       400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train(lingNet, ling_train_set, ling_test_set, ling_test_y, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9298403c",
      "metadata": {
        "id": "9298403c",
        "outputId": "ded5a85d-5123-4020-9c6a-35b3250f548f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.6090214252471924 for epoch 0\n",
            "train loss 0.6474200487136841 for epoch 1\n",
            "train loss 0.9084160327911377 for epoch 2\n",
            "train loss 0.41185396909713745 for epoch 3\n",
            "train loss 0.5989606380462646 for epoch 4\n",
            "train loss 0.8005595207214355 for epoch 5\n",
            "train loss 0.9279309511184692 for epoch 6\n",
            "train loss 1.2301185131072998 for epoch 7\n",
            "train loss 0.6267765164375305 for epoch 8\n",
            "train loss 0.8288030624389648 for epoch 9\n",
            "400\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.74      0.63       191\n",
            "           1       0.66      0.45      0.54       209\n",
            "\n",
            "    accuracy                           0.59       400\n",
            "   macro avg       0.60      0.60      0.58       400\n",
            "weighted avg       0.61      0.59      0.58       400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train(morphNet, morph_train_set, morph_test_set, morph_test_y, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd31162f",
      "metadata": {
        "id": "bd31162f",
        "outputId": "9e3f2e40-8775-4b81-ddea-78da6065a963"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.5595694780349731 for epoch 0\n",
            "train loss 0.0908379927277565 for epoch 1\n",
            "train loss 0.7321755886077881 for epoch 2\n",
            "train loss 0.02971639670431614 for epoch 3\n",
            "train loss 0.0012288884026929736 for epoch 4\n",
            "train loss 0.5677809119224548 for epoch 5\n",
            "train loss 0.0002944036095868796 for epoch 6\n",
            "train loss 0.23128077387809753 for epoch 7\n",
            "train loss 5.960446742392378e-06 for epoch 8\n",
            "train loss 0.005863370839506388 for epoch 9\n",
            "400\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.60      0.62       204\n",
            "           1       0.61      0.64      0.63       196\n",
            "\n",
            "    accuracy                           0.62       400\n",
            "   macro avg       0.62      0.62      0.62       400\n",
            "weighted avg       0.62      0.62      0.62       400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train(tfIdfNet, tf_idf_train_set, tf_idf_test_set, tf_idf_test_y, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5950facf",
      "metadata": {
        "id": "5950facf"
      },
      "source": [
        "# Выводы/Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для каждого набора признаков была обучена нейронная сеть со следующими параметрками:\n",
        "* 3 линейных слоя\n",
        "* размер скрытого слоя - 32\n",
        "* скорость обучения - 0.001\n",
        "* 10 эпох обучения\n",
        "* оптимизатор Adam\n",
        "* функция потерь - nll_loss\n",
        "\n",
        "## Результаты обучения\n",
        "\n",
        "| Features | F1 score |\n",
        "|----------|----------|\n",
        "| Лингвистические | 0.55 |\n",
        "| Морфологические | 0.59 |\n",
        "| TF-IDF | 0.62 |\n",
        "\n",
        "Как итог, при одинаковой конфигурации нейронной сети, лучшие результаты были получены для набора признаков TF-IDF\n",
        "\n",
        "For each set of features, a neural network was trained with the following parameters:\n",
        "* 3 line layers\n",
        "* hidden layer size - 32\n",
        "* learning rate - 0.001\n",
        "* 10 learning epochs\n",
        "* Adam optimizer\n",
        "* loss function - nll_loss\n",
        "\n",
        "As a result, with the same neural network configuration, the best results were obtained for the TF-IDF feature set"
      ],
      "metadata": {
        "id": "dcjqmH-Nt57s"
      },
      "id": "dcjqmH-Nt57s"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ed53763a",
        "c9c9ee2f",
        "537396ad",
        "a0b35137",
        "5950facf"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}